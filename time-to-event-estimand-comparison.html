<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Comparing Time-to-Event Estimands with Treatment Switching</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="RWE_tutorial.html">Introduction: TL Roadmap in RWE</a>
</li>
<li>
  <a href="step0.html">Causal roadmap and case study introduction</a>
</li>
<li>
  <a href="step1v2.html">Roadmap step 1-alt</a>
</li>
<li>
  <a href="step1a.html">Roadmap step 1a</a>
</li>
<li>
  <a href="step1b.html">Roadmap step 1b</a>
</li>
<li>
  <a href="step2.html">Roadmap step 2</a>
</li>
<li>
  <a href="step3.html">Roadmap step 3</a>
</li>
<li>
  <a href="step4.html">Roadmap step 4</a>
</li>
<li>
  <a href="step5.html">Roadmap step 5</a>
</li>
<li>
  <a href="PS_analysis.html">Propensity score matching analysis</a>
</li>
<li>
  <a href="appendix.html">Appendix</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Comparing Time-to-Event Estimands with
Treatment Switching</h1>

</div>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In an observational study comparing two drugs on time-to-event
outcomes (e.g. time to acute kidney injury, AKI), patients may switch
from one drug to the other during follow-up. Such treatment changes (a
type of intercurrent event) complicate the definition of the “treatment
effect” because the simple comparison of original groups no longer
reflects patients staying on their initial therapy. Different analytic
approaches correspond to different estimands – precise targets of
estimation – in this context. We discuss three key estimands for
time-to-event data with switching:</p>
<ol style="list-style-type: decimal">
<li><strong>Intention-to-Treat (ITT) Analysis</strong>: Classify and
analyze patients by the drug they started on, ignoring any subsequent
switching.</li>
<li><strong>Censoring at Time of Switching</strong>: Treat a switch as a
censoring event – patients are censored (their follow-up is cut off)
once they switch treatments, so only time on the initial drug is
considered.</li>
<li><strong>Inverse Probability of Censoring Weighting (IPCW)</strong>:
Use statistical weights to adjust for potentially informative censoring
due to switching. This estimates the hypothetical causal effect as if
patients had remained on their initial drug without switching.</li>
</ol>
<p>Each approach answers a slightly different question and has distinct
statistical interpretations, assumptions, pros/cons, and implications
for bias and causal inference. Below, we explain each estimand in
detail.</p>
</div>
<div id="intention-to-treat-itt-estimand" class="section level2">
<h2>1. Intention-to-Treat (ITT) Estimand</h2>
<div id="statistical-interpretation" class="section level3">
<h3>Statistical Interpretation</h3>
<p>In an ITT analysis, patients are analyzed according to their initial
treatment (the drug they started on), regardless of any switches
afterward. This mirrors the usual ITT principle from randomized trials –
it estimates the effect of treatment assignment or initiation as a
strategy. Essentially, ITT compares groups as originally allocated (or
chosen), reflecting the treatment policy effect: “start drug A versus
start drug B,” including all real-world behavior thereafter (switching,
adherence, etc.). The outcome contrast (e.g. hazard ratio for AKI) from
ITT reflects differences in time to AKI based on initial therapy choice,
allowing patients to do whatever happened in practice after that. It
does not attempt to disentangle the effects of switching – those are
considered part of the natural course under each initial treatment.</p>
</div>
<div id="assumptions" class="section level3">
<h3>Assumptions</h3>
<p>In a randomized trial, ITT is unbiased because randomization balances
confounders at baseline. In an observational study, however, initial
treatment choice may be confounded by patient characteristics. A valid
ITT-type analysis in this context assumes we have adequately controlled
or accounted for baseline differences between the groups (no unmeasured
baseline confounding of the drug selection). If we adjust for all
relevant baseline covariates (using regression, matching, etc.), we
approximate a comparison as if treatment assignment were random.</p>
<p>ITT also assumes the definition of the groups remains fixed despite
switching – i.e. a patient’s outcome is attributed to their start drug
(consistency assumption). Unlike per-protocol approaches, ITT does not
require assumptions about the switching process because it simply
ignores switches (treats them as part of the outcome of the strategy).
There is no need for “no informative censoring” here, since no censoring
is done at switch; all patients are followed for outcome regardless of
switching, so no selection occurs post-baseline.</p>
<p>Thus, the primary assumptions for ITT estimand validity are baseline
comparability (no unmeasured confounding) and that the measured outcome
indeed reflects the effect of initial treatment policy.</p>
</div>
<div id="advantages" class="section level3">
<h3>Advantages</h3>
<p>ITT is straightforward and avoids bias from post-initiation
selection. By including all patients as originally grouped, it preserves
the comparability established at baseline (in trials, this preserves
randomization; in observational studies, it preserves the
matching/adjustment).</p>
<p>It captures a pragmatic effect – the real-world effectiveness of
choosing one drug versus the other, inclusive of switching patterns and
non-adherence that occur in practice. This can be valuable for policy or
clinical decision-making: ITT tells us, for example, “if we start
patients on Drug A rather than Drug B, what is the difference in AKI
risk over time, given that some may switch or stop treatment as
observed?”</p>
<p>It is often considered conservative; if switching dilutes differences
between drugs, the ITT estimate of effect size will be closer to null
(smaller) than the per-protocol effect. ITT analyses use all available
outcome data (patients aren’t dropped or censored due to switching),
which maximizes sample size and generally provides more stable
estimates. Moreover, ITT is conceptually simple and reproducible,
requiring no complex modeling of post-baseline events.</p>
<p>Because of these properties, ITT is the default approach in
randomized trials and can be applied in observational studies as an
“as-initially-treated” analysis.</p>
</div>
<div id="disadvantages" class="section level3">
<h3>Disadvantages</h3>
<p>The ITT estimand does not answer the question of staying on the
initial drug. If the scientific question is “what is the effect of
continuously taking Drug A vs continuously taking Drug B on AKI risk?”,
ITT is misaligned with that because it allows patients to switch.</p>
<p>In situations with frequent or differential switching, ITT can
“dilute” the true treatment effect. For example, if Drug A truly has a
higher AKI risk but many high-risk patients on A quickly switch to Drug
B, the ITT analysis might underestimate A’s harm because those patients
(who might have had AKI on A) are counted in the A group but didn’t stay
on A for long. Indeed, it’s known that ITT analyses often fail to fully
capture the causal effect of treatment in the presence of treatment
switching.</p>
<p>In one real trial (ALTA-1L), the ITT hazard ratio for an outcome was
0.81, whereas an analysis that accounted for no switching estimated a
hazard ratio of 0.50 – the ITT analysis was much closer to 1 (no
difference), indicating a diluted effect when switches were allowed.
Thus, ITT can mask the full benefit or harm of a treatment if many
patients cross over to the other therapy.</p>
<p>Another limitation in observational ITT analyses is that baseline
confounding must be addressed; unlike an RCT, simply grouping by initial
treatment could be biased if, say, healthier patients tended to start
Drug A. Failure to adjust for confounders will compromise the ITT
comparison. Even with adjustment, unmeasured confounders can still bias
the ITT estimate in an observational study (this caveat applies to all
causal analyses on observational data).</p>
<p>Finally, ITT’s inclusion of all post-switch outcomes means it’s an
“intention-to-treat effect” rather than a “pure drug effect” – for
instance, if many in the Drug A group eventually switched to Drug B, the
ITT result is partly comparing a strategy that often ends up on B versus
the group that started on B (a muddling of treatments). This can make
interpretation tricky if switching is very common or occurs early.</p>
</div>
<div id="implications-for-bias-and-causal-inference"
class="section level3">
<h3>Implications for Bias and Causal Inference</h3>
<p>When its assumptions are met, ITT provides an unbiased estimate of
the effect of initial treatment strategy. In a randomized trial, this is
the primary analysis because it preserves randomization and avoids
biases from non-random dropout or crossover. In an observational study,
an ITT-like approach (after baseline adjustment) can similarly estimate
a causal effect of choosing one drug initially, so long as no residual
confounding exists.</p>
<p>Importantly, ITT does not introduce selection bias due to switching
because it does not condition on any post-initiation event – everyone is
followed regardless of what happens. Thus, problems like informative
censoring or time-varying confounding due to switching do not affect the
internal validity of the ITT estimand; all such post-baseline prognostic
differences are essentially baked into the effect being estimated.</p>
<p>However, because ITT mixes in the effects of patients changing
treatments, it estimates a different causal effect than a per-protocol
approach. We might call the ITT effect a “treatment policy estimand” (in
ICH E9 terminology) – the effect of starting Drug A versus Drug B under
usual clinical practice (where switching can occur). This is a perfectly
valid causal estimand, but it may not be the one of interest if we want
to know the efficacy of sustained treatment.</p>
<p>In summary, ITT is robust against bias from post-baseline selection
but may yield a biased answer to a different question if our goal is the
hypothetical effect of no switching. It is appropriate when we are
interested in a pragmatic, real-world effect of initial treatment
choice. It becomes less appropriate if our aim is to infer the effect of
continuous use of a drug (for that, per-protocol estimands are more
suitable).</p>
</div>
<div id="when-to-use-itt" class="section level3">
<h3>When to Use ITT</h3>
<p>Use an ITT approach when you want a pragmatic comparison of the two
treatment strategies as implemented in practice. For example, health
policy decisions or prescribing guidelines might favor ITT-like evidence
since it reflects what happens when patients are started on a drug
(including any switches or discontinuations).</p>
<p>ITT is the right choice if treatment switching is considered part of
the clinical pathway and you want to account for its impact in the
outcome. In randomized trials, ITT is standard to avoid bias; in
observational studies, an ITT-style analysis (with confounding control)
is often a good starting point or primary analysis for
effectiveness.</p>
<p>It is also useful when switching is infrequent or the differences in
outcomes are expected to persist despite some switching – under those
conditions, ITT and per-protocol effects will be similar.</p>
<p>On the other hand, if switching is very common and one wants the
unconfounded effect of staying on therapy, ITT alone may not be
sufficient (it would be used in conjunction with a per-protocol analysis
for a full picture).</p>
<p>In practice, one might report ITT as the main result (since it uses
all data and is straightforward), and then explore how switching may
have influenced results via additional methods like IPCW.</p>
<p>In summary, ITT is appropriate for estimating the effect of initial
treatment choice in a scenario where treatment changes occur, but it
implicitly folds in the consequences of those changes into the effect
estimate.</p>
</div>
</div>
<div id="censoring-at-time-of-switching-per-protocol-analysis"
class="section level2">
<h2>2. Censoring at Time of Switching (Per-Protocol Analysis)</h2>
<div id="statistical-interpretation-1" class="section level3">
<h3>Statistical Interpretation</h3>
<p>Censoring at the time of switching is a form of per-protocol
analysis. Here, each patient is followed only as long as they remain on
their initial therapy; if they switch to the other drug, we censor their
data at that switch point. Essentially, we pretend the patient is “lost
to follow-up” once they deviate from the original treatment. This
approach attempts to compare outcomes while on the originally assigned
drug, thereby aiming to estimate the effect as if patients had adhered
to their initial treatment throughout.</p>
<p>In a time-to-AKI analysis, this means we compare the time until AKI
for Drug A vs Drug B, counting only the period on the first drug for
each patient. Any AKI events that occur after a switch are not
attributed to the initial drug (since that person’s follow-up was cut
off at switch). Formally, this method is defining the estimand as the
survival experience under no switching, but it obtains it by literally
discarding (censoring) data once switching happens.</p>
<p>For example, if a patient on Drug A switches to Drug B at 6 months
without experiencing AKI by then, that patient’s follow-up is censored
at 6 months in the Drug A group; similarly, a patient originally on B
who switches to A would be censored at switch in the B group. We then
compare the censored time-to-event data between groups (often via
Kaplan-Meier curves or Cox models). The idea is to approximate what
would have happened if everyone stayed on their initial drug up to the
time of event or end of study.</p>
</div>
<div id="assumptions-1" class="section level3">
<h3>Assumptions</h3>
<p>The critical assumption for validity of this approach is
non-informative censoring at the time of switching. “Non-informative”
means that the reason a patient switches (and thus is censored) is
unrelated to their underlying risk of the outcome (after accounting for
known factors). In other words, those who switch at a given time should
be, on average, similar in prognosis to those who continue therapy at
that time.</p>
<p>This is a very strong assumption and often unrealistic: in practice,
treatment switching is often informative – patients may switch drugs
because of symptoms, side effects, or lack of efficacy, all of which are
related to outcome risk. For instance, if a patient on Drug A shows
early signs of kidney dysfunction, the doctor might switch them to Drug
B to prevent AKI; that patient was at high risk for AKI, and censoring
them at the switch removes an impending event from the Drug A group.
This violates non-informative censoring because the act of switching
carries information about the patient’s outcome risk.</p>
<p>Formally, we have selection bias if switching is associated with
patient characteristics or intermediate outcomes that also affect AKI
risk. Unless we adjust for those characteristics, the comparison of
“adherers” in each group will be biased.</p>
<p>In a randomized trial, we start with balanced groups at baseline, but
post-randomization switching can break that balance: one group may
preferentially retain lower-risk patients (those who tolerate the drug)
while high-risk patients leave. In an observational study, we have both
baseline confounding and time-varying confounding to consider – simply
censoring at switch does not by itself control either.</p>
<p>Thus, the censoring-at-switch analysis assumes: (1) we have
eliminated baseline confounding (e.g. via baseline covariate adjustment,
similar to ITT assumption), and (2) conditional on baseline factors, the
decision to switch is not driven by any unmeasured risk factors for the
outcome (or equivalently, that we could treat censoring as independent
of outcome given observed data).</p>
<p>Without additional adjustment, assumption (2) is essentially saying
switching is “as good as random” after controlling baseline – a very
strong condition. In reality, meeting this would require that either
almost no one switches (so it doesn’t matter), or switching happens for
idiosyncratic reasons unrelated to health status.</p>
<p>If we have measured time-varying indicators (like lab tests, blood
pressure, etc.) that predict switching, one could in theory stratify or
adjust for those to make the censoring closer to non-informative.
However, standard survival analysis with simple censoring typically does
not account for time-varying confounders without specialized
methods.</p>
<p>Summary of assumptions: All confounders of treatment selection and
switching are accounted for, and treatment switching is not driven by
factors related to outcome risk (no informative censoring). If these
hold, censoring at switching can recover the hypothetical estimand of no
switching; if not, bias results.</p>
</div>
<div id="advantages-1" class="section level3">
<h3>Advantages</h3>
<p>The primary appeal of censoring at switching is that it focuses on
the effect of staying on the initial treatment, which is often the
causal effect of interest. By removing patients at the moment they
deviate, we attempt to compare “clean” groups of adherers: Drug A group
represents outcomes if kept on A, Drug B group if kept on B. This can
reveal larger differences if one drug is truly better or worse, which
ITT might have masked.</p>
<p>In the earlier example, if Drug A is nephrotoxic, the ITT analysis
might underestimate that harm due to patients switching off A; censoring
at switch would more directly capture the high AKI incidence among those
who would stay on A.</p>
<p>Another practical advantage is simplicity: censoring at an event is a
standard technique in survival analysis. One can implement this easily
by treating the switch date as a censoring time in the dataset, without
requiring advanced modeling.</p>
<p>It uses each patient’s data up until they switch, which is more
efficient than outright excluding all switchers from the analysis
(excluding wastes all data from those patients, whereas censoring uses
them until switch). Indeed, censoring is generally preferred over
excluding entire patients because it at least keeps the pre-switch
follow-up.</p>
<p>The approach can be useful as a sensitivity analysis alongside ITT:
large differences between ITT and the censored analysis indicate that
switching had a big impact on outcomes. If switching is rare or happens
late, a censor-at-switch analysis will yield results similar to ITT (and
in that scenario, bias from censoring is minimal because few are
censored).</p>
<p>In summary, the censoring approach is conceptually aligned with a
per-protocol effect (estimating efficacy under full adherence) and is
easy to execute with available survival analysis tools.</p>
</div>
<div id="disadvantages-1" class="section level3">
<h3>Disadvantages</h3>
<p>The major drawback is potential bias from informative censoring. If
patients who switch are systematically different in risk, the results
will be skewed. This method can essentially compare a non-random subset
of patients on Drug A to a non-random subset on Drug B.</p>
<p>For example, suppose high-risk patients on A tend to switch to B
early (perhaps due to early signs of renal problems), whereas low-risk
patients on A stay. Meanwhile, on Drug B maybe fewer switch or they
switch for different reasons. The naive per-protocol analysis will then
find that the remaining Drug A patients have relatively good outcomes
(because the ones prone to AKI left early and got censored), making Drug
A look safer than it truly is.</p>
<p>In general, per-protocol analyses without proper adjustment are
“prone to selection bias when intervention deviation (switching) is
associated with time-varying confounders that also influence outcomes”.
This selection bias can lead to an overestimate or underestimate of the
true effect.</p>
<p>Another disadvantage is loss of information: by censoring at switch,
we ignore what happened to patients after they switched. Those outcomes
might still be relevant (especially if a patient switches and then
immediately has AKI, ITT would count that toward the original group’s
failure, but the per-protocol censored analysis drops it entirely).</p>
<p>Censoring reduces effective sample size and statistical power, since
events that occur after switch are not counted and follow-up time is
truncated. If a large fraction of patients switch, the analysis may end
up with few events and wide confidence intervals.</p>
<p>There is also complexity in interpretation: the resulting estimate
ostensibly applies to a scenario of “no switching,” but because it’s
biased if switching was informative, it’s unclear exactly what
population or condition it represents.</p>
<p>In essence, naively censoring introduces uncertainty about validity –
we might get a result, but we must question if it reflects causation or
just selection.</p>
<p>Lastly, per-protocol analyses in trials break the protection of
randomization; in observational studies, they exacerbate confounding
issues by conditioning on post-baseline factors. For these reasons,
guidelines caution against simple per-protocol comparisons unless you
can argue switching was negligible or random.</p>
</div>
<div id="implications-for-bias-and-causal-inference-1"
class="section level3">
<h3>Implications for Bias and Causal Inference</h3>
<p>If (and only if) switching is non-informative (independent of outcome
risk given baseline covariates), censoring at switching would yield an
unbiased estimate of the causal effect under no switching. In that ideal
case, it answers the question “how do outcomes compare if everyone
remained on their initial drug until event or study end?” and could be
interpreted causally.</p>
<p>However, when switching is influenced by patient prognosis or
intermediate outcomes (the usual case), this approach fails to produce a
valid causal effect. The estimate can be seen as a biased per-protocol
effect, because the comparability of groups is “broken” once we
condition on staying vs switching.</p>
<p>Essentially, the act of switching is a collider of prior factors and
outcomes – conditioning on it (via censoring) opens a backdoor path for
confounding. Without special methods, the censored analysis does not
account for time-varying confounders that both affect switching and
outcome, thus introducing selection bias.</p>
<p>In causal inference terms, this method is only valid under a strong
assumption of “no unmeasured confounders for adherence” and no feedback
between treatment and risk; if that assumption fails, the estimand from
this analysis is not equal to the true causal effect we want.</p>
<p>Practically, epidemiologists consider the simple censoring approach
as potentially misleading – it might show a treatment effect, but part
of that difference could be due to who remained on therapy rather than
the therapy itself. For example, per-protocol analysis often
overestimates treatment efficacy in trials because patients who adhere
tend to be healthier or more motivated. In the AKI example, it might
underestimate harm if those at risk left early.</p>
<p>Therefore, from a causal inference standpoint, a naive per-protocol
analysis is usually viewed as biased, and techniques like IPCW or other
G-methods are recommended to properly estimate the causal effect of
continuous treatment.</p>
<p>In summary: censoring at switching targets the hypothetical estimand
of no switching, but it will only reflect the true causal effect under
stringent conditions that rarely strictly hold without further
adjustment. Analysts should interpret results with caution, considering
the direction and magnitude of possible selection bias.</p>
</div>
<div id="when-to-use-censoring-at-switch" class="section level3">
<h3>When to Use Censoring-at-Switch</h3>
<p>This approach may be used as a secondary or sensitivity analysis,
especially in randomized trials or well-controlled studies, to explore
what the effect might be under full adherence. It is appropriate when
the goal is to approximate a per-protocol effect and one is aware of the
bias risk.</p>
<p>Situations where this might be reasonable include: (a) Minimal
switching – if &lt;5% of patients switch, censoring them likely won’t
distort the comparison much, and the primary impact is just a slight
loss of power. (b) External reasons for switching – e.g. if a drug was
withdrawn from market for reasons unrelated to patient health, those
switches might be fairly random with respect to AKI risk, making
censoring less problematic. (c) No ability to model switching – if the
dataset lacks detailed information on why/when patients switch
(precluding advanced methods), one might present a per-protocol analysis
with caveats, rather than no analysis of adherence at all. (d) Trial
protocols – in some trials, a per-protocol analysis (often implemented
by censoring or excluding switchers) is requested by regulators or
investigators to see efficacy among completers; again, it must be
interpreted alongside ITT.</p>
<p>In observational research, one would very rarely rely on a
censored-at-switch result as the definitive finding due to confounding
concerns, but it can be illustrative.</p>
<p>Importantly, whenever censoring at switching is used, one should
check for and discuss the potential bias. Modern analytic frameworks
(like the ICH E9 estimand framework) actually discourage naive
per-protocol without accounting for informative censoring.</p>
<p>Thus, while this method is conceptually aligned with a “no-switch”
estimand, a better approach to achieve that estimand is to use IPCW or
related methods. Use simple censoring only if you have good reason to
believe it approximates random censoring or if you are using it as a
baseline for more advanced corrections.</p>
</div>
</div>
<div id="inverse-probability-of-censoring-weighting-ipcw-estimand"
class="section level2">
<h2>3. Inverse Probability of Censoring Weighting (IPCW) Estimand</h2>
<div id="statistical-interpretation-2" class="section level3">
<h3>Statistical Interpretation</h3>
<p>IPCW is a causal inference method to correctly estimate the effect of
a treatment strategy in a hypothetical scenario where switching does not
occur. Like the censoring approach, IPCW will censor patients at the
moment they switch drugs (treating those times as end of follow-up for
the original treatment). However, IPCW doesn’t simply drop those
patients; instead, it assigns weights to the remaining uncensored
patients to compensate for those who were censored.</p>
<p>Intuitively, IPCW creates a “pseudo-population” in which no one
switches by up-weighting individuals who stay on their initial treatment
to represent those who left. The weight at any given time for a patient
who is still on their original drug is the inverse of the probability
that they would have remained uncensored (not switched) up to that time,
given their covariates.</p>
<p>Thus, if a certain type of patient (with specific characteristics) is
likely to switch early, then patients of that type who miraculously
haven’t switched are given a high weight to stand in for the others. By
doing so, IPCW adjusts for the selection bias from informative
censoring, restoring the comparability between groups as if neither had
switching.</p>
<p>In practical terms, one fits a model for the time-to-switch (or
probability of staying on initial treatment) as a function of relevant
covariates (which can be time-updated), then uses the inverse of that
predicted probability to weight each person’s contribution to the
survival analysis. The weighted analysis (e.g. weighted Kaplan-Meier or
weighted Cox model) then estimates the hazard or survival for each group
under the hypothetical intervention of full adherence.</p>
<p>As one source explains, “IPCW works by censoring at [the time of
deviation] and giving weights to uncensored participants to recover the
broken balance of prognostic characteristics. The weight is the inverse
of the probability of remaining uncensored given the values of baseline
and time-varying confounders.”</p>
<p>This yields an estimate of what the time-to-AKI distribution would
have been if patients had never switched drugs, by accounting for the
fact that certain patients were more likely to switch.</p>
<p>In summary, IPCW targets the same estimand as the per-protocol
approach (effect of Drug A vs Drug B if everyone stayed on their initial
drug), but does so in a way that controls for the factors that led to
switching. It is one of the “G-methods” in causal analysis for
time-varying treatments, specifically estimating a hypothetical estimand
where the intercurrent event (switching) is eliminated.</p>
</div>
<div id="assumptions-2" class="section level3">
<h3>Assumptions</h3>
<p>IPCW, like any causal method, has its own assumptions for validity.
The key assumptions are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>No unmeasured confounders (for censoring)</strong> – All
variables that influence both the likelihood of switching and the risk
of AKI must be measured and included in the weighting model. If there
are unrecorded reasons for switching that also affect outcomes
(e.g. subtle clinical signs of renal trouble that weren’t captured),
then even IPCW will be biased because the model cannot adjust for those.
This assumption is essentially the same as saying treatment switching is
conditionally random given the covariates we accounted for.</p></li>
<li><p><strong>Positivity</strong>: Every patient, at every time point,
has some positive probability of not switching (and of switching) given
their covariate history. If there is a subgroup of patients who always
switch immediately (or conversely never switch) no matter what, then we
cannot construct a valid weight (the inverse probability would blow up
to infinity or be undefined). Positivity means we have enough overlap –
for every combination of predictors, there are examples of patients who
continued on their drug, so we can use them to represent
others.</p></li>
<li><p><strong>Correct model specification</strong>: The model used to
estimate the switching probability (or hazard of switching) must be
correctly specified (or at least not severely mis-modeled). IPCW
requires modeling the relationship between covariates and switching; if
this model is wrong (omits non-linear terms, interactions, etc.), the
weights may be incorrect and introduce bias. Usually one uses
diagnostics to check stabilized weights, etc., but the assumption is
that we can adequately model the censoring process.</p></li>
<li><p><strong>Independent censoring aside from modeled
factors</strong>: We assume that any censoring (including administrative
end of study or loss-to-follow-up) or other competing risks are either
handled or not informative in a way not accounted by weights. Often IPCW
is combined with assumptions of no other biases like informative
loss-to-follow-up beyond measured covariates.</p></li>
<li><p><strong>Consistency</strong>: If we say we’re estimating “no
switching” outcomes, we assume that a patient who did not switch has the
same outcome risk as they would under a hypothetical world where they
were not allowed to switch (this is a standard consistency assumption –
the observed outcomes correspond to the defined treatment
strategies).</p></li>
</ol>
<p>In essence, if our weights perfectly balance the groups with respect
to confounders, we assume that the remaining differences in outcomes are
due to the treatment effect.</p>
<p>All these assumptions are strong but are analogous to assumptions
made in other causal inference methods. Particularly, no unmeasured
confounding for the switching process is crucial – IPCW “inherits” this
requirement because we treat the switching as a quasi-random (after
conditioning) event. Violation of this (say doctors switch high-risk
patients based on clinical judgment that isn’t fully captured in the
data) will lead to biased results.</p>
<p>It’s worth noting that these assumptions are often unverifiable from
the data; one must rely on subject-matter knowledge to argue they are
reasonable.</p>
</div>
<div id="advantages-2" class="section level3">
<h3>Advantages</h3>
<p>When its assumptions hold, IPCW provides an unbiased estimate of the
causal effect of staying on initial treatment (vs switching),
effectively correcting the bias that the simple censoring approach would
have introduced.</p>
<p>The big advantage is that we do not have to throw away information or
assume switching is random; instead, we explicitly model the switching
behavior. By up-weighting patients who remain on therapy, we account for
the fact that those who remain may be a select subset, thus realigning
them to represent the original population.</p>
<p>This method allows us to answer the clinically relevant hypothetical
question: “What would the risk of AKI be if patients had never switched
from their initial drug?” with a sound statistical footing.</p>
<p>Another advantage is that IPCW uses all available data up until a
patient switches. Like the censoring approach, a patient’s follow-up
contributes information until the switch, but unlike a naive approach,
their premature departure is compensated for by weights rather than
ignored. This tends to produce less biased and more efficient estimates
than excluding switchers entirely.</p>
<p>IPCW can handle time-varying confounders that are affected by past
treatment – something standard regression cannot do properly. For
example, if blood creatinine is rising (a time-varying covariate) due to
being on Drug A, and that prompts switching and also predicts AKI, IPCW
can include current creatinine in the model for switching and thus
adjust for that “treatment-confounder feedback”.</p>
<p>Traditional Cox models with time-dependent covariates would fail to
give a causal estimate in that scenario, but IPCW (or other G-methods)
can address it by appropriate weighting or modeling.</p>
<p>Another advantage is generalizability of the estimand: the IPCW
result corresponds to a clearly defined hypothetical intervention (no
switching), which stakeholders (clinicians, decision-makers) often want
to know about. In the ALTA-1L trial example, decision-makers were
interested in overall survival if patients stayed on the originally
assigned drug; IPCW enabled estimating that (and found a much larger
effect than ITT).</p>
<p>So IPCW aligns analysis with the question of drug efficacy/pure
effect. Technically, IPCW is relatively straightforward to implement
with modern statistical software (though conceptually advanced): one
fits a logistic or survival model for censoring and then applies weights
in a Cox model – many epidemiologic analyses have used this, so it’s a
well-established method.</p>
<p>Compared to more complex methods like g-formulas or structural
models, IPCW is often easier to apply and understand (it’s analogous to
weighting for inverse probability of treatment, which many are familiar
with).</p>
<p>Finally, when done correctly, IPCW ameliorates selection bias and
thus tends to produce estimates closer to the truth than per-protocol
without weighting. In summary, the advantage of IPCW is that it lets us
retain a causal interpretation for a per-protocol estimand without
sacrificing rigor: we get the answer to “what if no one switched?” in an
unbiased way (assuming confounders accounted).</p>
</div>
<div id="disadvantages-2" class="section level3">
<h3>Disadvantages</h3>
<p>The IPCW approach comes with greater complexity and some statistical
challenges. First, it requires modeling the switching process, which
demands careful consideration and sufficient data. If the model is
misspecified or important predictors are omitted, the weights may not
fully remove bias.</p>
<p>There is also a risk of extreme weights: if some patients have a very
low probability of staying on treatment (i.e. nearly everyone like them
would switch), the inverse probability will be very large for any who
didn’t switch. Such extreme weights can lead to instability – high
variance in estimates and wide confidence intervals, or even convergence
issues. Analysts often stabilize weights or truncate extremely large
weights to mitigate this, but that introduces some bias-variance
tradeoff.</p>
<p>Another issue is that IPCW relies on strong assumptions (no
unmeasured confounding) that, as noted, are not testable. If this
assumption is violated, IPCW can give a false sense of security – the
result is precise but still biased. In contrast, a wildly different
per-protocol result versus ITT at least alerts you that something’s up;
a flawed IPCW might yield a number that seems plausible but hides
residual confounding.</p>
<p>Implementation-wise, one must decide on the correct set of covariates
(including time-varying ones) to include in the weight model. Including
too many irrelevant covariates can increase variance (through unstable
weights), while missing key ones causes bias. Thus, IPCW requires
expertise to choose and model predictors of switching appropriately.</p>
<p>Another disadvantage is efficiency: although IPCW uses available data
efficiently, heavily weighted analyses can effectively reduce the
“effective sample size.” If many patients switch early, the analysis is
essentially carried by fewer weighted observations, which can result in
less precise estimates than ITT.</p>
<p>Standard error estimation must account for the weighting (robust or
sandwich variance estimators, or bootstrapping, are often used), which
is another layer of complexity.</p>
<p>From a communication standpoint, IPCW results might be harder to
explain to clinicians or policymakers unfamiliar with the method. For
instance, it may be puzzling that the “hypothetical no-switch” effect is
different from the observed reality (ITT); one has to explain the
concept of weighting and causal estimands.</p>
<p>Finally, IPCW generally addresses bias from measured confounders; it
cannot fix bias due to fundamentally different patient populations if
switching is extremely common in one group – in such cases, one might
have little information about what would happen if those patients stayed
(lack of positivity).</p>
<p>In short, the disadvantages of IPCW are the heavy reliance on model
quality and data richness, the potential for high variance due to
weighting, and the complexity in execution and interpretation.</p>
</div>
<div id="implications-for-bias-and-causal-inference-2"
class="section level3">
<h3>Implications for Bias and Causal Inference</h3>
<p>Under the core assumptions, IPCW will produce an estimate of the
causal effect of the two drugs under a policy of no switching that is as
unbiased as one could get from the given data. It addresses the
selection bias that afflicts the simple censored analysis by effectively
re-balancing the treatment groups at each time point with respect to
prognostic factors.</p>
<p>This means we can interpret the weighted hazard ratio or survival
difference as the per-protocol effect: “Drug A vs Drug B if patients had
remained on their initial treatment throughout.” This is powerful for
causal inference because it answers the question of comparative efficacy
(as opposed to ITT’s comparative effectiveness).</p>
<p>For example, if IPCW finds Drug A has a significantly higher hazard
of AKI than Drug B in the no-switch scenario, we infer that
intrinsically A is more nephrotoxic; any attenuation in ITT was due to
switching patterns.</p>
<p>IPCW estimates are consistent with the idea of emulating a target
trial where switching is not allowed – it’s as if we ran a trial
instructing patients to stay on their assigned drug, and measured AKI
outcomes.</p>
<p>Of course, the causal validity hinges on no unmeasured confounding:
if an important predictor of switching and outcome was left out, then
the IPCW result is still biased (though we often expect it’s less biased
than unweighted per-protocol).</p>
<p>One should always perform diagnostics on the weights; if weights are
extreme or if weighted covariate balance is not achieved, it calls into
question the reliability of the causal inference.</p>
<p>When done properly, IPCW is regarded as a reliable method in causal
inference to handle time-varying treatment and censoring. It’s one of
the simpler g-methods (others include g-formula and marginal structural
models) that can recover the causal estimand of interest.</p>
<p>In the context of AKI, IPCW would allow us to say: “Based on
observational data,</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
