---
title: "HCV Treatment and Kidney Injury: A Simulation-Based Case Study"
author: "Andrew Mertens"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.width = 10, fig.height = 6, 
                      fig.align = "center")
```

# Overview

This document simulates and analyzes data for a case study on HCV treatment and kidney injury. This is based on a real post-market comparative safety analysis that assessed the risk of acute kidney injury (AKI) in patients with chronic hepatitis C virus (HCV) who were treated with sofosbuvir (SOF)-containing direct-acting antivirals (DAAs) compared to non-SOF DAAs. The study used real-world data from the HealthVerity database, including administrative claims and electronic medical records, to conduct a retrospective cohort analysis. The study applied propensity score matching (PSM) to balance baseline characteristics between treatment groups and used Cox proportional hazards models to estimate the hazard ratio (HR) of AKI incidence. The primary objective was to determine whether exposure to SOF-containing DAAs was associated with a higher risk of AKI compared to non-SOF DAAs. The steps include:

1. Data simulation with realistic confounding relationships
2. Introduction of missing data following realistic patterns
3. Exploratory data analysis and visualization
4. Missing data handling through random forest imputation
5. Calculation of true causal effects (for simulation reference)

## Setting up the environment

```{r load-libraries}
# Load necessary libraries
library(MASS)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(naniar)       # For missing data visualization
library(tableone)     # For summary tables
library(missForest)   # For random-forest based imputation

# Set seed for reproducibility
set.seed(42)
```

# Part 1: Data Simulation

We'll simulate data for a study examining whether HCV treatment reduces the risk of kidney injury. The simulation will include:

- Baseline covariates (age, sex, diabetes, hypertension, GFR, BMI)
- Treatment assignment with realistic confounding
- Time-to-event outcome (kidney injury) with censoring
- Introduction of realistic missing data patterns

## Simulate baseline covariates and treatment

```{r simulate-covariates}
# Define sample size
n <- 5000

# Simulate baseline covariates
age <- rnorm(n, mean = 60, sd = 10)  # Age centered at 60
sex <- rbinom(n, 1, 0.5)  # Binary sex variable (0 or 1)
diabetes <- rbinom(n, 1, 0.3)  # 30% prevalence of diabetes
hypertension <- rbinom(n, 1, 0.4)  # 40% prevalence of hypertension
baseline_gfr <- rnorm(n, mean = 90, sd = 15)  # Baseline kidney function (eGFR)
bmi <- rnorm(n, mean = 28, sd = 5)  # BMI distribution

# Introduce non-linearity in the relationship between age and treatment
age_effect <- exp(-0.05 * (age - 60)^2)  # Exponential effect centered at 60

# Interaction terms affecting treatment assignment
interaction_term <- (diabetes * hypertension) + 0.5 * (sex * bmi)

# Simulate treatment assignment (propensity depends on confounders non-linearly)
treatment_prob <- plogis(-1 + 0.02 * age + 0.4 * diabetes + 0.3 * hypertension +
                         0.2 * sex + 0.01 * baseline_gfr + 0.02 * bmi +
                         interaction_term - age_effect)

treatment <- rbinom(n, 1, treatment_prob)
```

## Simulate outcome (kidney injury) and censoring

```{r simulate-outcome}
# Introduce non-linearity in the relationship between age and outcome
age_outcome_effect <- sin(age / 10)

# Simulate time to kidney injury outcome (survival outcome)
baseline_hazard <- 0.02  # Baseline hazard rate
outcome_prob <- plogis(-2 + 0.03 * age + 0.5 * diabetes + 0.4 * hypertension +
                       0.3 * sex + 0.015 * baseline_gfr + 0.025 * bmi +
                       interaction_term - 0.5 * treatment - age_outcome_effect)

event <- rbinom(n, 1, outcome_prob)  # Binary outcome for kidney injury

# Simulate time-to-event (higher probabilities lead to shorter time-to-event)
time_to_event <- rexp(n, rate = baseline_hazard * (1 + outcome_prob))

# Censor some observations randomly
censoring_time <- rexp(n, rate = 1/10)  # Administrative censoring at random times
observed_time <- pmin(time_to_event, censoring_time)
censored <- as.integer(time_to_event > censoring_time)

# Create a data frame
df <- data.frame(
  age, sex, diabetes, hypertension, baseline_gfr, bmi,
  treatment, event, time_to_event, observed_time, censored
)
```

## Introduce realistic missing data patterns

In real-world studies, missing data follows patterns related to observable characteristics. We'll introduce missingness that depends on observed variables to create a more realistic dataset.

```{r introduce-missingness}
# Set seed for reproducibility of missingness
set.seed(123)

# 1. Age: Missingness probability depends on diabetes status and deviation from age 60.
df <- df %>%
  mutate(
    p_age_missing = plogis(-2 + 0.05 * diabetes + 0.01 * (age - 60)),
    age = ifelse(runif(n()) < p_age_missing, NA, age)
  )

# 2. Baseline kidney function (baseline_gfr): Missingness depends on hypertension and the current gfr value.
df <- df %>%
  mutate(
    p_gfr_missing = plogis(-1 + 0.03 * hypertension - 0.01 * baseline_gfr),
    baseline_gfr = ifelse(runif(n()) < p_gfr_missing, NA, baseline_gfr)
  )

# 3. BMI: Missingness influenced by sex and age.
df <- df %>%
  mutate(
    p_bmi_missing = plogis(-1.5 + 0.02 * sex + 0.01 * (age - 60)),
    bmi = ifelse(runif(n()) < p_bmi_missing, NA, bmi)
  )

# 4. Outcome (event): Missingness probability depends on age, diabetes, and treatment status.
# Here, we assume that being treated (treatment == 1) reduces the probability of missing outcome data.
df <- df %>%
  mutate(
    p_event_missing = plogis(-1 + 0.03 * age - 0.5 * diabetes - 0.5 * treatment),
    event = ifelse(runif(n()) < p_event_missing, NA, event)
  )

# Remove the temporary probability columns
df <- df %>% subset(., select=-c(p_age_missing, p_gfr_missing, p_bmi_missing, p_event_missing))
```

## Calculate true causal effects (for simulation reference)

One advantage of simulation is that we know the true causal effect, which allows us to validate our methods.

```{r calculate-truth}
# Define the function for probability of kidney injury
calc_risk <- function(age, diabetes, hypertension, sex, baseline_gfr, bmi, interaction_term, treatment) {
  lin_pred <- -2 + 0.03 * age + 0.5 * diabetes + 0.4 * hypertension +
    0.3 * sex + 0.015 * baseline_gfr + 0.025 * bmi + interaction_term - 0.5 * treatment
  return(1 / (1 + exp(-lin_pred)))
}

# Compute expected risks under treatment and no treatment
df <- df %>%
  mutate(
    risk_treated = calc_risk(age, diabetes, hypertension, sex, baseline_gfr, bmi, 
                             (diabetes * hypertension + 0.5 * sex * bmi), 1),
    risk_untreated = calc_risk(age, diabetes, hypertension, sex, baseline_gfr, bmi, 
                               (diabetes * hypertension + 0.5 * sex * bmi), 0)
  )

# Compute true causal estimand
true_risk_treated <- mean(df$risk_treated, na.rm = TRUE)
true_risk_untreated <- mean(df$risk_untreated, na.rm = TRUE)

true_risk_difference <- true_risk_treated - true_risk_untreated
true_risk_ratio <- true_risk_treated / true_risk_untreated

# Print results
cat("True Risk (Treated):", round(true_risk_treated, 4), "\n")
cat("True Risk (Untreated):", round(true_risk_untreated, 4), "\n")
cat("True Risk Difference (RD):", round(true_risk_difference, 4), "\n")
cat("True Risk Ratio (RR):", round(true_risk_ratio, 4), "\n")
```

## Save simulated data

```{r save-simulated-data, eval=FALSE}
# Save to CSV
write.csv(df, "data/simulated_case_study_data.csv", row.names = FALSE)
```

# Part 2: Exploratory Data Analysis and Missing Data Handling

Now that we have simulated the data, we'll explore it and handle missing values.

## Initial data exploration

```{r data-exploration}
# Check summary statistics
summary(df[, c("age", "sex", "diabetes", "hypertension", "baseline_gfr", "bmi", "treatment", "event")])

# Visualize missingness patterns across variables
vis_miss(df)

# Create a summary table of key covariates (including missingness information)
covariate_vars <- c("age", "baseline_gfr", "bmi", "sex", "diabetes", "hypertension")
table1 <- CreateTableOne(vars = covariate_vars, data = df, test = FALSE)
print(table1, missing = TRUE)
```

## Visualize distributions of key variables

```{r visualize-distributions}
# Histogram for Age
ggplot(df, aes(x = age)) +
  geom_histogram(binwidth = 2, fill = "skyblue", color = "black", na.rm = TRUE) +
  labs(title = "Histogram of Age (non-missing)", x = "Age", y = "Frequency") +
  theme_minimal()

# Histogram for Baseline GFR
ggplot(df, aes(x = baseline_gfr)) +
  geom_histogram(binwidth = 2, fill = "lightgreen", color = "black", na.rm = TRUE) +
  labs(title = "Histogram of Baseline GFR (non-missing)", x = "Baseline GFR", y = "Frequency") +
  theme_minimal()

# Histogram for BMI
ggplot(df, aes(x = bmi)) +
  geom_histogram(binwidth = 1, fill = "lightcoral", color = "black", na.rm = TRUE) +
  labs(title = "Histogram of BMI (non-missing)", x = "BMI", y = "Frequency") +
  theme_minimal()
```

## Examine relationships between variables

```{r relationships}
# Scatter plot: Age vs. Baseline GFR, colored by diabetes status
ggplot(df, aes(x = age, y = baseline_gfr, color = factor(diabetes))) +
  geom_point(alpha = 0.6, na.rm = TRUE) +
  labs(title = "Age vs. Baseline GFR", x = "Age", y = "Baseline GFR", color = "Diabetes") +
  theme_minimal()

# Treatment by covariates
ggplot(df, aes(x = factor(treatment), y = age)) +
  geom_boxplot(na.rm = TRUE) +
  labs(title = "Age by Treatment Status", x = "Treatment", y = "Age") +
  theme_minimal()

# Event by treatment
df %>%
  filter(!is.na(event) & !is.na(treatment)) %>%
  group_by(treatment) %>%
  summarise(event_rate = mean(event)) %>%
  ggplot(aes(x = factor(treatment), y = event_rate)) +
  geom_col(fill = "steelblue") +
  labs(title = "Unadjusted Event Rate by Treatment", 
       x = "Treatment", y = "Event Rate") +
  theme_minimal()
```

## Missing data imputation using Random Forest

We'll use the missForest algorithm to impute missing values in covariates.

```{r imputation}
# Select the covariates to impute
covariates_to_impute <- c("age", "baseline_gfr", "bmi")

# Create a subset for imputation
df_cov <- df[, covariates_to_impute]

# Apply missForest for imputation (using default settings, which uses random forest)
impute_result <- missForest(df_cov, verbose = TRUE)

# Extract the imputed data
df_cov_imputed <- impute_result$ximp

# Replace original covariates in the full dataset with the imputed values
df_imputed <- df
df_imputed[, covariates_to_impute] <- df_cov_imputed
```

## Diagnostics after imputation

```{r post-imputation-diagnostics}
# Check that missingness in the imputed covariates is removed
sapply(df_imputed[, covariates_to_impute], function(x) sum(is.na(x)))

# Confirm that the outcome variable remains with its original missingness pattern
cat("Missing values in outcome (event):", sum(is.na(df_imputed$event)), "\n")

# Compare distributions before and after imputation
par(mfrow = c(1, 3))

# Age comparison
hist(df$age, main = "Original Age", col = "lightblue", border = "white", xlab = "Age", na.rm = TRUE)
hist(df_imputed$age, main = "Imputed Age", col = "lightcoral", border = "white", xlab = "Age")

# GFR comparison
hist(df$baseline_gfr, main = "Original GFR", col = "lightblue", border = "white", 
     xlab = "Baseline GFR", na.rm = TRUE)
hist(df_imputed$baseline_gfr, main = "Imputed GFR", col = "lightcoral", border = "white", 
     xlab = "Baseline GFR")

# BMI comparison
hist(df$bmi, main = "Original BMI", col = "lightblue", border = "white", xlab = "BMI", na.rm = TRUE)
hist(df_imputed$bmi, main = "Imputed BMI", col = "lightcoral", border = "white", xlab = "BMI")

par(mfrow = c(1, 1))
```

## Save the imputed dataset

```{r save-imputed-data, eval=FALSE}
# Save the imputed dataset
write.csv(df_imputed, "data/imputed_case_study_data.csv", row.names = FALSE)
```

# Next Steps

This case study has:
1. Generated a simulated dataset with realistic features
2. Introduced missingness consistent with real-world patterns
3. Explored the data and imputed missing values
4. Calculated the true causal effect for simulation validation

The imputed dataset is now ready for causal inference analysis methods like:
- G-computation
- TMLE (Targeted Maximum Likelihood Estimation)
- Inverse probability weighting
- Hazard-based methods with outcome model adjustment

Given the complete data generation process, we can compare the estimated causal effects from these methods with the...

(keep writing)


##Case Study: Real-World Evidence for a New Treatment – Hepatitis C Therapy and Kidney Injury

#### Context: Our  example comes from a collaborative effort (including Gilead) to apply the causal roadmap in a pharmacoepidemiology setting. Suppose we are interested in whether a new Hepatitis C virus (HCV) treatment affects the risk of developing acute kidney injury (AKI) within one year of starting therapy. HCV treatments in the past had known nephrotoxic effects, but newer direct-acting antivirals are generally safer – so a relevant question for clinicians could be: does curing HCV with the new drug improve kidney outcomes (or conversely, does the drug have any adverse effect on kidneys)? This is a typical RWE scenario using, say, a large electronic health record database where patients who initiated the new HCV drug are compared to similar patients who did not receive that treatment. The outcome is time-to-AKI, a time-to-event outcome.
Roadmap Application: Following the causal inference roadmap, the investigators first define the causal question clearly: “Does treatment with the new HCV drug cause a reduction in 12-month risk of acute kidney injury compared to no treatment (or standard care)?” The estimand was chosen as the 12-month risk difference in AKI between the treated and untreated groups​
file-74gjcvidaigkrg6dqikmtv
. This estimand is straightforward and clinically interpretable – it directly answers how much absolute risk is lowered (or raised) by the treatment at one year. Notably, this is different from just fitting a Cox model and reporting a hazard ratio; the roadmap encourages thinking of measures like risk differences or risk ratios at a concrete time point, which are easier to communicate. The target trial approach was used to specify eligibility (patients with HCV eligible for treatment), treatment strategies (start the new drug vs. defer treatment during that period), and outcome (AKI within 12 months).
In terms of design, they likely used an observational cohort from the RWD, employing methods to emulate randomization (like propensity score matching or weighting initially). Indeed, a tutorial built around this case study walks through multiple analytic approaches – propensity score matching, inverse probability weighting, and then targeted learning (TMLE) – to show the differences​
file-74gjcvidaigkrg6dqikmtv
. The roadmap was used to pre-specify these approaches for comparison (with TMLE planned as the primary analysis to estimate the 12-month risk difference). Confounders such as baseline kidney function, comorbidities (diabetes, hypertension), age, etc., were identified in the causal model step and included in the adjustment via either propensity scores or the outcome regression in TMLE.
Findings: While the full results of this hypothetical example are part of a teaching tutorial rather than a published study, the exercise revealed important conceptual lessons. First, it demonstrated the limitations of the Cox model/HR for causal interpretation in this context​
file-74gjcvidaigkrg6dqikmtv
. The Cox model might yield a hazard ratio for AKI, but if the proportional hazards assumption is violated or if the hazard ratio changes over time, interpreting it as “the effect” is problematic. For instance, a hazard ratio of 0.8 could correspond to very different absolute risk differences depending on baseline risk; moreover, if treatment mostly delays AKI rather than prevents it, the HR is not constant. The roadmap approach, by targeting the risk difference, directly answers the question: “By how many percentage points does the treatment change the 1-year risk of AKI?” – which stakeholders find more directly useful. In the tutorial, they highlight that one must “understand [the] limitations [of hazard ratios] for causal interpretation” and consider alternative estimands​file-74gjcvidaigkrg6dqikmtv.
Second, when applying TMLE with Super Learner, the analysis illustrated how using a flexible ensemble for confounder adjustment can reveal nonlinear or interaction effects that a simple propensity score model might miss. For example, if the effect of HCV treatment on AKI risk differs in patients with pre-existing kidney disease, a parametric model might not capture this, whereas a machine learning model could. The TMLE, by combining outcome modeling and weighting, provided an estimate of the risk difference with a valid confidence interval. The comparison of methods (PS matching, IPW, TMLE) showed that all methods agreed qualitatively (say, treatment improved outcomes) but TMLE had certain advantages: it made full use of the data (no need to discard unmatched patients as in matching), potentially achieved greater precision by using all covariate information, and was less sensitive to model misspecification than a one-shot propensity score approach.
Third, this case underscored some practical challenges and how the roadmap addresses them: one challenge was how to handle patients who maybe stopped or switched treatments (intercurrent events). The roadmap’s emphasis on explicitly stating how such events are handled (e.g., treating them as censoring or integrating them into the outcome definition) ensured that the analysis was consistent with the causal question. Another challenge was positivity – ensuring that for each combination of confounders, there were both treated and untreated patients to compare. In RWE, if certain high-risk patients always get treated, then we have no data on similar patients untreated, making causal inference impossible in that subgroup. The planning stages would catch that (via checking data distributions), and the analysis might then be restricted to a subpopulation where overlap was sufficient, or a targeted extrapolation technique could be used. The case study likely dealt with this by, for example, not trying to estimate effects in extremely ill patients if all of them were treated.
Overall, the HCV-AKI example showed the end-to-end application of the roadmap: from formulating a clear question to choosing an estimand (risk difference), executing a TMLE analysis, and comparing it to more familiar methods. The lesson learned is that even for those new to causal inference, following the roadmap demystifies the process and yields more interpretable results. By the end of the tutorial, a reader can see how each step of the roadmap concretely improved the analysis: the estimand selection made results clinically meaningful; the careful design and use of appropriate methods reduced bias; and the comparison of methods increased confidence that the findings were not an artifact of one particular analytic choice. This kind of case study, drawn from a collaboration involving industry analysts and academic statisticians, also exemplifies how communication is improved – the roadmap provides a common language (estimand, assumptions, etc.) that both epidemiologists and statisticians can discuss, making the analysis more transparent to all stakeholders.




