---
title: "Targeted Maximum Likelihood Estimation (TMLE) Analysis"
author: "Causal Inference Analysis"
date: "March 3, 2025"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.width = 10, fig.height = 6, dpi = 300)
```

# Introduction

This document performs causal inference analysis using Targeted Maximum Likelihood Estimation (TMLE) on an observational dataset. TMLE is a doubly robust method that combines machine learning for both the outcome model and the propensity score model, with a targeting step that optimizes the parameter of interest.

Unlike traditional methods, TMLE:
1. Allows flexible modeling using machine learning algorithms
2. Provides protection against model misspecification through its doubly robust property
3. Yields asymptotically efficient estimates with valid statistical inference

We'll compare TMLE results with previous Inverse Probability Weighting (IPW) analyses to assess consistency across methods.

## Loading Required Libraries

```{r load-libraries}
# Load necessary libraries
library(tmle)           # For targeted maximum likelihood estimation
library(SuperLearner)   # For the Super Learner algorithm
library(dplyr)          # For data manipulation
library(ggplot2)        # For visualization
library(tableone)       # For creating descriptive tables
library(pROC)           # For ROC curves
library(caret)          # For model evaluation metrics
library(ipw)            # For comparison with IPW methods
library(survey)         # For weighted analyses
library(cobalt)         # For balance assessment
```

# Data Preparation

## Loading the Dataset

```{r load-data}
# Load the cleaned and imputed dataset
df <- read.csv("data/imputed_case_study_data.csv")

# Display the structure of the dataset
str(df)

# Show the first few rows
head(df)

# Summary statistics
summary(df[, c("age", "baseline_gfr", "bmi", "treatment", "event")])

# Check for missing values
colSums(is.na(df))
```

# Exploratory Data Analysis

Before diving into the causal analysis, let's explore the dataset to understand the distribution of key variables and their relationships with treatment assignment.

```{r eda}
# Distribution of treatment
table(df$treatment)
prop.table(table(df$treatment))

# Distribution of outcome by treatment group
table(df$treatment, df$event)
prop.table(table(df$treatment, df$event), margin = 1)

# Create balance table before any adjustment
covariates <- c("age", "baseline_gfr", "bmi", "sex", "diabetes", "hypertension")
baseline_table <- CreateTableOne(vars = covariates, strata = "treatment", data = df, test = TRUE)
print(baseline_table, smd = TRUE)
```

```{r visualization}
# Visualize the distribution of key continuous variables by treatment
# Age distribution
ggplot(df, aes(x = age, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  labs(title = "Age Distribution by Treatment Group", 
       x = "Age", y = "Density", fill = "Treatment") +
  theme_minimal()

# Baseline GFR distribution
ggplot(df, aes(x = baseline_gfr, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  labs(title = "Baseline GFR Distribution by Treatment Group", 
       x = "Baseline GFR", y = "Density", fill = "Treatment") +
  theme_minimal()

# BMI distribution
ggplot(df, aes(x = bmi, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  labs(title = "BMI Distribution by Treatment Group", 
       x = "BMI", y = "Density", fill = "Treatment") +
  theme_minimal()

# Categorical variables
# Sex distribution
ggplot(df, aes(x = factor(sex), fill = factor(treatment))) +
  geom_bar(position = "dodge") +
  labs(title = "Sex Distribution by Treatment Group", 
       x = "Sex (1 = Male, 0 = Female)", y = "Count", fill = "Treatment") +
  theme_minimal()

# Diabetes distribution
ggplot(df, aes(x = factor(diabetes), fill = factor(treatment))) +
  geom_bar(position = "dodge") +
  labs(title = "Diabetes Distribution by Treatment Group", 
       x = "Diabetes (1 = Yes, 0 = No)", y = "Count", fill = "Treatment") +
  theme_minimal()

# Hypertension distribution
ggplot(df, aes(x = factor(hypertension), fill = factor(treatment))) +
  geom_bar(position = "dodge") +
  labs(title = "Hypertension Distribution by Treatment Group", 
       x = "Hypertension (1 = Yes, 0 = No)", y = "Count", fill = "Treatment") +
  theme_minimal()

# Outcome by treatment
ggplot(df, aes(x = factor(treatment), fill = factor(event))) +
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("steelblue", "tomato"), 
                    labels = c("No Event", "Event")) +
  labs(title = "Outcome Distribution by Treatment Group", 
       x = "Treatment", y = "Proportion", fill = "Outcome") +
  theme_minimal()
```

# Step 1: Estimate Propensity Scores

Although TMLE will estimate propensity scores internally, it's useful to examine them separately for comparison with IPW approaches.

**to do! update this to use SuperLearner**

```{r propensity-score}
# Model treatment as a function of key covariates using logistic regression
ps_model <- glm(treatment ~ age + baseline_gfr + bmi + sex + diabetes + hypertension,
                data = df, family = binomial)

# Summary of the propensity score model
summary(ps_model)

# Obtain the predicted propensity scores
df$pscore <- predict(ps_model, type = "response")

# Visualize propensity score distribution by treatment group
ggplot(df, aes(x = pscore, fill = factor(treatment))) +
  geom_density(alpha = 0.5) +
  labs(title = "Propensity Score Distribution by Treatment Group",
       x = "Propensity Score", y = "Density", fill = "Treatment") +
  theme_minimal()

# Assess propensity score model performance
roc_ps <- roc(df$treatment, df$pscore)
auc_ps <- auc(roc_ps)
plot(roc_ps, main = paste("Propensity Score Model ROC Curve (AUC =", round(auc_ps, 3), ")"))

# Check for positivity (common support)
# Create bins of propensity scores
df$ps_bin <- cut(df$pscore, breaks = seq(0, 1, 0.1))
counts <- table(df$ps_bin, df$treatment)
prop_table <- prop.table(counts, margin = 1)
print(counts)
print(prop_table)

# Visualize overlap
ggplot(df, aes(x = ps_bin, fill = factor(treatment))) +
  geom_bar(position = "stack") +
  labs(title = "Treatment Assignment by Propensity Score Bins",
       x = "Propensity Score Bins", y = "Count", fill = "Treatment") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Step 2: Simple Outcome Model

Before applying TMLE, let's fit a simple outcome model to understand the unadjusted relationship.

```{r outcome-model}
# Simple outcome model without adjustment
simple_model <- glm(event ~ treatment, data = df, family = binomial)
summary(simple_model)

# Extract odds ratio and confidence interval
or_simple <- exp(coef(simple_model)["treatment"])
or_ci_simple <- exp(confint(simple_model)["treatment", ])
simple_results <- data.frame(
  OR = or_simple,
  Lower_CI = or_ci_simple[1],
  Upper_CI = or_ci_simple[2]
)
print(simple_results)

# Outcome model adjusted for covariates
adjusted_model <- glm(event ~ treatment + age + baseline_gfr + bmi + sex + diabetes + hypertension, 
                     data = df, family = binomial)
summary(adjusted_model)

# Extract odds ratio and confidence interval
or_adjusted <- exp(coef(adjusted_model)["treatment"])
or_ci_adjusted <- exp(confint(adjusted_model)["treatment", ])
adjusted_results <- data.frame(
  OR = or_adjusted,
  Lower_CI = or_ci_adjusted[1],
  Upper_CI = or_ci_adjusted[2]
)
print(adjusted_results)
```

# Step 3: Define Variables for TMLE

```{r tmle-prep}
# Outcome variable: 'event' (binary indicator for kidney injury)
Y=df$event
A=df$treatment
W=df %>% select(age, baseline_gfr, bmi, sex, diabetes, hypertension)
```

# Step 4: Specify the Super Learner Library

Super Learner is an ensemble algorithm that combines predictions from multiple machine learning methods to optimize predictive performance.

```{r sl-library}
# Define a Super Learner library with a mix of parametric and machine learning algorithms
SL.library <- c("SL.glm",      # Standard logistic regression
                "SL.glmnet",   # LASSO/elastic-net regression
                "SL.ranger",   # Random forest (via ranger)
                "SL.xgboost")  # Gradient boosting

# You can add more learners (e.g., "SL.nnet") if desired
```

# Step 5: Implement TMLE

Now we'll implement TMLE, which integrates both the outcome model and propensity score model in a targeted approach.

```{r tmle-implementation}
# Set seed for reproducibility
set.seed(123)

# Use the tmle() function to estimate the causal effect
# The family is set to "binomial" since the outcome is binary
tmle_fit <- tmle(Y = Y, A = A, W = W,
                 family = "binomial",
                 Q.SL.library = SL.library,
                 g.SL.library = SL.library)

# Print a summary of the TMLE results
print(tmle_fit)
```

# Step 6: Review and Interpret TMLE Output

```{r tmle-results}
# Extract key results from the TMLE output
tmle_ate <- tmle_fit$estimates$ATE$psi
tmle_ate_se <- sqrt(tmle_fit$estimates$ATE$var.psi)
tmle_ci_lower <- tmle_fit$estimates$ATE$CI[1]
tmle_ci_upper <- tmle_fit$estimates$ATE$CI[2]
tmle_pvalue <- tmle_fit$estimates$ATE$pvalue

tmle_results <- data.frame(
  Method = "TMLE",
  ATE = tmle_ate,
  SE = tmle_ate_se,
  CI_Lower = tmle_ci_lower,
  CI_Upper = tmle_ci_upper,
  P_value = tmle_pvalue
)
print(tmle_results)

# Extract estimated risks under treatment and control
risk_treated <- tmle_fit$estimates$EY1$psi
risk_control <- tmle_fit$estimates$EY0$psi
risk_diff <- risk_treated - risk_control
risk_ratio <- tmle_fit$estimates$RR$psi

risk_summary <- data.frame(
  Risk_Under_Treatment = risk_treated,
  Risk_Under_Control = risk_control,
  Risk_Difference = risk_diff,
  Risk_Ratio = risk_ratio
)
print(risk_summary)
```

# Step 7: Visualize TMLE Estimates

```{r tmle-visualization}
# Add predicted probabilities to the dataframe
df$Qbar1 <- tmle_fit$Qstar[,2]  # predicted outcome if treated
df$Qbar0 <- tmle_fit$Qstar[,1]  # predicted outcome if untreated

# Distribution of predicted outcomes under treatment and control
ggplot(df) +
  geom_histogram(aes(x = Qbar1), binwidth = 0.05, fill = "steelblue", alpha = 0.5) +
  geom_histogram(aes(x = Qbar0), binwidth = 0.05, fill = "tomato", alpha = 0.5) +
  labs(title = "Predicted Outcome Probabilities under Treatment vs. Control",
       x = "Predicted Probability of Event", y = "Frequency") +
  theme_minimal() +
  annotate("text", x = 0.75, y = 150, 
           label = paste("Mean under treatment:", round(mean(df$Qbar1), 3))) +
  annotate("text", x = 0.75, y = 140, 
           label = paste("Mean under control:", round(mean(df$Qbar0), 3)))

# Individual treatment effects
df$ite <- df$Qbar1 - df$Qbar0

# Distribution of individual treatment effects
ggplot(df, aes(x = ite)) +
  geom_histogram(binwidth = 0.02, fill = "purple", color = "black", alpha = 0.7) +
  geom_vline(xintercept = mean(df$ite), color = "red", linetype = "dashed", size = 1) +
  labs(title = "Distribution of Individual Treatment Effects",
       x = "Individual Treatment Effect (Risk Difference)", y = "Frequency") +
  theme_minimal() +
  annotate("text", x = max(df$ite) * 0.7, y = 100, 
           label = paste("Average Treatment Effect:", round(mean(df$ite), 3)))

# Forest plot for comparison with other methods
methods <- c("Unadjusted", "Covariate-Adjusted", "TMLE")
estimates <- c(coef(simple_model)["treatment"], coef(adjusted_model)["treatment"], tmle_ate)
lower_ci <- c(confint(simple_model)["treatment", 1], 
              confint(adjusted_model)["treatment", 1], 
              tmle_ci_lower)
upper_ci <- c(confint(simple_model)["treatment", 2], 
              confint(adjusted_model)["treatment", 2], 
              tmle_ci_upper)

results_df <- data.frame(
  Method = factor(methods, levels = methods),
  Estimate = estimates,
  Lower_CI = lower_ci,
  Upper_CI = upper_ci
)

ggplot(results_df, aes(x = Estimate, y = Method)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = Lower_CI, xmax = Upper_CI), height = 0.2) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Treatment Effect Estimates by Method",
       x = "Effect Estimate", y = "") +
  theme_minimal()
```

# Step 8: Examine Super Learner Results

# TO DO: debug getting the weights out!

```{r superlearner-results, eval=FALSE}
# Examine the Super Learner weights to see which algorithms contributed most
# For the treatment model (propensity score)
g_weights <- tmle_fit$g$SL.weights
g_weights_df <- data.frame(
  Algorithm = names(g_weights),
  Weight = g_weights
)
g_weights_df <- g_weights_df[order(g_weights_df$Weight, decreasing = TRUE), ]
print("Super Learner Weights for Treatment Model:")
print(g_weights_df)

# For the outcome model
q_weights <- tmle_fit$Q$SL.weights
q_weights_df <- data.frame(
  Algorithm = names(q_weights),
  Weight = q_weights
)
q_weights_df <- q_weights_df[order(q_weights_df$Weight, decreasing = TRUE), ]
print("Super Learner Weights for Outcome Model:")
print(q_weights_df)

# Visualize the weights
ggplot(g_weights_df, aes(x = reorder(Algorithm, -Weight), y = Weight)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Super Learner Weights for Treatment Model",
       x = "Algorithm", y = "Weight") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(q_weights_df, aes(x = reorder(Algorithm, -Weight), y = Weight)) +
  geom_bar(stat = "identity", fill = "tomato") +
  labs(title = "Super Learner Weights for Outcome Model",
       x = "Algorithm", y = "Weight") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Step 9: Comparison with IPW Method

# TO DO: debug IPW comparison!

To directly compare with our previous IPW analysis, let's implement IPW and compare the results.

```{r ipw-comparison, eval=FALSE}
# Calculate stabilized weights
pA1 <- mean(df$treatment == 1)
pA0 %>%
  mutate(stab_weight = ifelse(treatment == 1, pA1 / pscore, pA0 / (1 - pscore)))

# Examine summary of weights
summary(df$stab_weight)

# Create a survey design object using the stabilized weights
design <- svydesign(ids = ~1, data = df, weights = ~stab_weight)

# Fit the weighted logistic regression model
ipw_model <- svyglm(event ~ treatment, design = design, family = binomial)
summary(ipw_model)

# Extract the IPW effect estimate
ipw_coef <- coef(ipw_model)["treatment"]
ipw_se <- sqrt(vcov(ipw_model)["treatment", "treatment"])
ipw_ci_lower <- ipw_coef - 1.96 * ipw_se
ipw_ci_upper <- ipw_coef + 1.96 * ipw_se

# Convert to risk difference scale for comparison with TMLE
# (Note: This is a simplification, not exact)
ipw_rd <- mean(plogis(predict(ipw_model, newdata = transform(df, treatment = 1)))) - 
           mean(plogis(predict(ipw_model, newdata = transform(df, treatment = 0))))

ipw_results <- data.frame(
  Method = "IPW",
  Effect_Log_Odds = ipw_coef,
  SE_Log_Odds = ipw_se,
  Lower_CI_Log_Odds = ipw_ci_lower,
  Upper_CI_Log_Odds = ipw_ci_upper,
  Risk_Difference_Approx = ipw_rd
)
print(ipw_results)

# Compare TMLE and IPW results
comparison <- data.frame(
  Method = c("IPW (Risk Diff Approx)", "TMLE"),
  Estimate = c(ipw_rd, tmle_ate),
  Lower_CI = c(NA, tmle_ci_lower),  # NA because these aren't directly comparable
  Upper_CI = c(NA, tmle_ci_upper)
)
print(comparison)

# Visualize comparison
ggplot(comparison, aes(x = Estimate, y = Method)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = Lower_CI, xmax = Upper_CI), height = 0.2) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Treatment Effect Estimates: TMLE vs. IPW",
       x = "Risk Difference", y = "") +
  theme_minimal()
```

# Step 10: Sensitivity Analysis

## 10.1: Alternative Outcome Model Specification

```{r alt-outcome-model}
# TMLE with a simpler Super Learner library for outcome model
simple_SL.library <- c("SL.glm", "SL.step")

tmle_simple_fit <- tmle(Y = Y, A = A, W = W,
                        family = "binomial",
                        Q.SL.library = simple_SL.library,
                        g.SL.library = SL.library)

print(tmle_simple_fit)

# Extract key results
tmle_simple_ate <- tmle_simple_fit$estimates$ATE$psi
tmle_simple_ate_se <- sqrt(tmle_simple_fit$estimates$ATE$var.psi)
tmle_simple_ci_lower <- tmle_simple_fit$estimates$ATE$CI[1]
tmle_simple_ci_upper <- tmle_simple_fit$estimates$ATE$CI[2]


tmle_simple_results <- data.frame(
  Method = "TMLE with Simple Outcome Model",
  ATE = tmle_simple_ate,
  SE = tmle_simple_ate_se,
  CI_Lower = tmle_simple_ci_lower,
  CI_Upper = tmle_simple_ci_upper
)

# Compare with main TMLE results
tmle_comparison <- rbind(
  data.frame(
    Method = "TMLE (Full)",
    ATE = tmle_ate,
    SE = tmle_ate_se,
    CI_Lower = tmle_ci_lower,
    CI_Upper = tmle_ci_upper
  ),
  tmle_simple_results
)
print(tmle_comparison)
```

## 10.2: Alternative Propensity Score Model Specification

```{r alt-ps-model}
# TMLE with a simpler Super Learner library for propensity score model
tmle_simple_ps_fit <- tmle(Y = Y, A = A, W = W,
                           family = "binomial",
                           Q.SL.library = SL.library,
                           g.SL.library = simple_SL.library)

print(tmle_simple_ps_fit)

# Extract key results
tmle_simple_ps_ate <- tmle_simple_ps_fit$estimates$ATE$psi
tmle_simple_ps_ate_se <- sqrt(tmle_simple_ps_fit$estimates$ATE$var.psi)
tmle_simple_ps_ci_lower <- tmle_simple_ps_fit$estimates$ATE$CI[1]
tmle_simple_ps_ci_upper <- tmle_simple_ps_fit$estimates$ATE$CI[2]

tmle_simple_ps_results <- data.frame(
  Method = "TMLE with Simple PS Model",
  ATE = tmle_simple_ps_ate,
  SE = tmle_simple_ps_ate_se,
  CI_Lower = tmle_simple_ps_ci_lower,
  CI_Upper = tmle_simple_ps_ci_upper
)

# Add to comparison
tmle_comparison <- rbind(tmle_comparison, tmle_simple_ps_results)
print(tmle_comparison)

# Visualize all TMLE sensitivity analyses
ggplot(tmle_comparison, aes(x = ATE, y = Method)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Sensitivity Analysis of TMLE Estimates",
       x = "Average Treatment Effect (Risk Difference)", y = "") +
  theme_minimal()
```

## 10.3: Influential Observations

#To do! Code this out:

```{r influential-obs, eval=FALSE}
# Calculate influence curves for TMLE
ic_threshold = NA

#CODE to ID influential observations below
XXX

print(paste("Number of potentially influential observations:", length(influential)))

if (length(influential) > 0) {
  print("Influential observations:")
  print(df[influential, ])
  
  # TMLE without influential observations
  tmle_no_infl_fit <- tmle(Y = Y[-influential], A = A[-influential], W = W[-influential, ],
                           family = "binomial",
                           Q.SL.library = SL.library,
                           g.SL.library = SL.library)
  
  tmle_no_infl_ate <- tmle_no_infl_fit$estimates$ATE
  tmle_no_infl_se <- sqrt(tmle_no_infl_fit$estimates$ATE.var)
  tmle_no_infl_ci_lower <- tmle_no_infl_ate - 1.96 * tmle_no_infl_se
  tmle_no_infl_ci_upper <- tmle_no_infl_ate + 1.96 * tmle_no_infl_se
  
  tmle_no_infl_results <- data.frame(
    Method = "TMLE without Influential Obs",
    ATE = tmle_no_infl_ate,
    SE = tmle_no_infl_se,
    CI_Lower = tmle_no_infl_ci_lower,
    CI_Upper = tmle_no_infl_ci_upper
  )
  
  # Add to comparison
  tmle_comparison <- rbind(tmle_comparison, tmle_no_infl_results)
  print(tmle_comparison)
}
```

# Step 11: Comprehensive Method Comparison

**Note: run after debugging IPW**

```{r comprehensive-comparison, eval=FALSE}
# Combine all methods for comparison
all_methods <- data.frame(
  Method = c("Unadjusted", 
             "Covariate-Adjusted", 
             "IPW", 
             "TMLE"),
  Estimate = c(coef(simple_model)["treatment"], 
               coef(adjusted_model)["treatment"], 
               ipw_coef,
               tmle_ate),
  SE = c(summary(simple_model)$coefficients["treatment", "Std. Error"], 
         summary(adjusted_model)$coefficients["treatment", "Std. Error"], 
         ipw_se,
         tmle_ate_se),
  Lower_CI = c(confint(simple_model)["treatment", 1], 
               confint(adjusted_model)["treatment", 1], 
               ipw_ci_lower,
               tmle_ci_lower),
  Upper_CI = c(confint(simple_model)["treatment", 2], 
               confint(adjusted_model)["treatment", 2], 
               ipw_ci_upper,
               tmle_ci_upper),
  Scale = c("Log Odds", "Log Odds", "Log Odds", "Risk Difference")
)

# Print the comprehensive comparison
print(all_methods)

# Create a table with method-specific results
log_odds_methods <- all_methods[all_methods$Scale == "Log Odds", ]
log_odds_methods$OR <- exp(log_odds_methods$Estimate)
log_odds_methods$OR_Lower_CI <- exp(log_odds_methods$Lower_CI)
log_odds_methods$OR_Upper_CI <- exp(log_odds_methods$Upper_CI)

print("Odds Ratio Results:")
print(log_odds_methods[, c("Method", "OR", "OR_Lower_CI", "OR_Upper_CI")])

print("Risk Difference Results:")
print(all_methods[all_methods$Scale == "Risk Difference", 
                 c("Method", "Estimate", "Lower_CI", "Upper_CI")])
```

# Conclusion

In this analysis, we've performed a comprehensive Targeted Maximum Likelihood Estimation (TMLE) to estimate the causal effect of treatment on the outcome, adjusting for observed confounding. The key advantages of TMLE include:

1. **Doubly robust property**: TMLE remains consistent if either the outcome model or the propensity score model is correctly specified.

2. **Machine learning flexibility**: TMLE uses Super Learner to optimize the prediction models, reducing model misspecification bias.

3. **Targeted parameter estimation**: TMLE focuses specifically on optimizing the parameter of interest (ATE) rather than the entire outcome model.

The results demonstrate that:

1. The TMLE estimated average treatment effect (ATE) was [value], indicating [interpretation].

2. This estimate was [similar/different] to the IPW estimate, providing [consistent/inconsistent] evidence about the treatment effect.

3. Sensitivity analyses showed [robustness/sensitivity] to model specification, suggesting that our findings are [reliable/should be interpreted with caution].

TMLE provides a robust approach to causal inference in observational studies, complementing traditional methods like IPW while offering additional methodological advantages.

